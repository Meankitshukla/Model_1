{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset from sklearn\n",
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "          \"dis\", \"tax\", \"ptratio\", \"medv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and named it columns\n",
    "training_set = pd.read_csv(\"boston_train.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "\n",
    "test_set = pd.read_csv(\"boston_test.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "\n",
    "prediction_set = pd.read_csv(\"boston_predict.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10) (100, 10) (6, 10)\n"
     ]
    }
   ],
   "source": [
    "# checkout the shape\n",
    "print(training_set.shape, test_set.shape, prediction_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling features and label columns\n",
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\n",
    "                 \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate feature columns\n",
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000C0EC306CF8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# define optimizer and estimator\n",
    "my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(    \n",
    "        feature_columns=feature_cols,   \n",
    "        model_dir=\"train\", optimizer=my_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining input function class\n",
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):    \n",
    "         return tf.estimator.inputs.pandas_input_fn(       \n",
    "         x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),       \n",
    "         y = pd.Series(data_set[LABEL].values),       \n",
    "         batch_size=n_batch,          \n",
    "         num_epochs=num_epochs,       \n",
    "         shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from train\\model.ckpt-1000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into train\\model.ckpt.\n",
      "INFO:tensorflow:loss = 82497.04, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 65.6309\n",
      "INFO:tensorflow:loss = 82374.58, step = 1101 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.6987\n",
      "INFO:tensorflow:loss = 82252.26, step = 1201 (1.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.7368\n",
      "INFO:tensorflow:loss = 82130.09, step = 1301 (1.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.5498\n",
      "INFO:tensorflow:loss = 82008.06, step = 1401 (1.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8298\n",
      "INFO:tensorflow:loss = 81886.19, step = 1501 (1.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.9701\n",
      "INFO:tensorflow:loss = 81764.47, step = 1601 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.3332\n",
      "INFO:tensorflow:loss = 81642.87, step = 1701 (1.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.5404\n",
      "INFO:tensorflow:loss = 81521.42, step = 1801 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8092\n",
      "INFO:tensorflow:loss = 81400.125, step = 1901 (1.048 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into train\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 74577.22.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0xc0e9947128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "estimator.train(input_fn=get_input_fn(training_set,                                       \n",
    "                                           num_epochs=None,                                      \n",
    "                                           n_batch = 128,                                      \n",
    "                                           shuffle=False),                                      \n",
    "                                           steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-14T18:35:19Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-14-18:35:21\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 527.42584, global_step = 2000, label/mean = 22.08, loss = 52742.586, prediction/mean = 0.40144965\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: train\\model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model wit test dataset\n",
    "ev = estimator.evaluate(    \n",
    "          input_fn=get_input_fn(test_set,                          \n",
    "          num_epochs=1,                          \n",
    "          n_batch = 128,                          \n",
    "          shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 52742.585938\n"
     ]
    }
   ],
   "source": [
    "# print the loss value\n",
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean      22.625500\n",
       "std        9.572593\n",
       "min        5.000000\n",
       "25%       16.600000\n",
       "50%       21.400000\n",
       "75%       25.025000\n",
       "max       50.000000\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['medv'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "y = estimator.predict(    \n",
    "         input_fn=get_input_fn(prediction_set,                          \n",
    "         num_epochs=1,                          \n",
    "         n_batch = 128,                          \n",
    "         shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Predictions: [array([0.25447795], dtype=float32), array([0.6718134], dtype=float32), array([0.2887641], dtype=float32), array([0.22756661], dtype=float32), array([0.6730065], dtype=float32), array([0.31221557], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# to print the estimated values\n",
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
